{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic_modelling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14PttEoeE54m",
        "outputId": "81d6a584-3918-4717-e5ef-a9306b362d7f"
      },
      "source": [
        "!pip install contractions\n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "from nltk.corpus import stopwords\n",
        "import contractions\n",
        "import numpy as np\n",
        "from gensim.models import LsiModel\n",
        "from gensim import models\n",
        "from gensim import corpora\n",
        "from gensim.similarities import MatrixSimilarity\n",
        "\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.52)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.0)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w219RaxLGWv",
        "outputId": "81bbe581-8cf8-49b1-de85-c9f7c12f6e80"
      },
      "source": [
        "#loading the corpus\n",
        "sents = nltk.Text(movie_reviews.sents())\n",
        "print(sents[0])\n",
        "print(\"No. of Documents: \",len(sents))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.']\n",
            "No. of Documents:  71532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UIX2X3HLyg-"
      },
      "source": [
        "ps = nltk.PorterStemmer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LstqJ_wML3SV"
      },
      "source": [
        "\n",
        "#remove contraction and stop words\n",
        "def removeContraction(sents_list):\n",
        "  new_sents = []\n",
        "  for s in sents_list:\n",
        "    words = []\n",
        "    for word in s:\n",
        "      word = contractions.fix(word)\n",
        "      word_split = word.split(' ')\n",
        "      for w in word_split:\n",
        "        if not w.lower() in stop_words:\n",
        "          words.append(w.lower())\n",
        "    if len(words) != 0:\n",
        "      new_sents.append(words)\n",
        "\n",
        "  return new_sents"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRRrunnZL5pV",
        "outputId": "a886dcfa-326b-47c1-a1d0-26b123c77210"
      },
      "source": [
        "sents = removeContraction(sents) #removing contraction for eg. I'll -> I will \n",
        "\n",
        "#pre-processing\n",
        "modified_sents = []\n",
        "for sent in sents:\n",
        "  words = []\n",
        "  for word in sent:\n",
        "       word = ps.stem(word) #performing stemming for e.g several -> sever\n",
        "       word = lemmatizer.lemmatize(word, pos=\"v\") #performing lemmitization for eg. running -> run\n",
        "       if word.isalpha():\n",
        "        words.append(word)\n",
        "  if len(words) != 0:\n",
        "    modified_sents.append(words)\n",
        "\n",
        "print(modified_sents[0])\n",
        "print(len(modified_sents))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['plot', 'two', 'teen', 'coupl', 'go', 'church', 'parti', 'drink', 'drive']\n",
            "67018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugo_iWb9MABL",
        "outputId": "0885a6bd-7031-4190-9bc2-5e6b85945bd2"
      },
      "source": [
        "#getting the vocabulary\n",
        "vocab = corpora.Dictionary(modified_sents)\n",
        "print(vocab)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary(25037 unique tokens: ['church', 'coupl', 'drink', 'drive', 'go']...)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwtdCgbcMHkE"
      },
      "source": [
        "doc_term_matrix = [vocab.doc2bow(tokens) for tokens in modified_sents]\n",
        "tfidf = models.TfidfModel(doc_term_matrix)\n",
        "corpus_tfidf = tfidf[doc_term_matrix]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAg66GzqMfYk"
      },
      "source": [
        "nltk.corpus.movie_reviews.fileids()\n",
        "lsi = models.LsiModel(corpus_tfidf, id2word=vocab)  # initialize an LSI transformation\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rOTqiq6NDO8",
        "outputId": "a6a33536-4df1-4241-936a-a7330300e7ee"
      },
      "source": [
        "from pprint import pprint\n",
        "pprint(lsi.print_topics(num_topics=3, num_words=25))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.315*\"film\" + 0.308*\"movi\" + 0.218*\"one\" + 0.170*\"like\" + 0.169*\"see\" + '\n",
            "  '0.169*\"make\" + 0.147*\"good\" + 0.141*\"get\" + 0.140*\"charact\" + 0.123*\"time\" '\n",
            "  '+ 0.116*\"go\" + 0.105*\"even\" + 0.103*\"know\" + 0.103*\"much\" + 0.100*\"well\" + '\n",
            "  '0.098*\"would\" + 0.096*\"realli\" + 0.095*\"scene\" + 0.094*\"think\" + '\n",
            "  '0.091*\"stori\" + 0.089*\"end\" + 0.088*\"thing\" + 0.088*\"say\" + 0.085*\"bad\" + '\n",
            "  '0.081*\"way\"'),\n",
            " (1,\n",
            "  '-0.849*\"movi\" + 0.427*\"film\" + 0.100*\"one\" + -0.093*\"see\" + 0.089*\"charact\" '\n",
            "  '+ -0.074*\"good\" + -0.068*\"bad\" + 0.052*\"stori\" + 0.049*\"scene\" + '\n",
            "  '-0.040*\"like\" + 0.035*\"get\" + 0.034*\"much\" + 0.033*\"even\" + 0.032*\"perform\" '\n",
            "  '+ 0.030*\"take\" + 0.027*\"two\" + 0.027*\"littl\" + 0.027*\"give\" + 0.026*\"best\" '\n",
            "  '+ 0.026*\"mr\" + 0.025*\"interest\" + 0.025*\"also\" + -0.025*\"funni\" + '\n",
            "  '0.024*\"way\" + 0.024*\"actor\"'),\n",
            " (2,\n",
            "  '0.718*\"see\" + -0.530*\"good\" + 0.203*\"go\" + 0.128*\"get\" + -0.123*\"make\" + '\n",
            "  '0.120*\"know\" + -0.110*\"bad\" + 0.102*\"one\" + -0.085*\"charact\" + 0.081*\"want\" '\n",
            "  '+ -0.071*\"perform\" + -0.065*\"movi\" + -0.060*\"film\" + 0.055*\"ever\" + '\n",
            "  '-0.054*\"pretti\" + -0.053*\"actor\" + -0.051*\"give\" + -0.047*\"act\" + '\n",
            "  '-0.045*\"look\" + -0.040*\"realli\" + -0.039*\"much\" + 0.039*\"never\" + '\n",
            "  '0.039*\"twice\" + -0.038*\"great\" + -0.037*\"cast\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiCLnZCQOQPy"
      },
      "source": [
        "topic 0 : good = 0.147 bad= 0.085 (good reviews)\n",
        "\n",
        "topic 1: good= -0.074 bad= -0.068 (mixed reviews)\n",
        "\n",
        "topic 2: good= -0.53 bad= -0.11 (bad reviews)"
      ]
    }
  ]
}